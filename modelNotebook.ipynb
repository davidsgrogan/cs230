{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import scipy.io.wavfile\n",
    "from python_speech_features import mfcc, delta\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just read file number 1 which contains 7305509 audio samples and is named cousinhenry_01_trollope_8khz.wav Now analying it:\n",
      "\t analyzing training sample number 500\n",
      "\t analyzing training sample number 1000\n",
      "\t analyzing training sample number 1500\n",
      "just read file number 2 which contains 12400013 audio samples and is named siegeofcorinth_2_byron_8khz.wav Now analying it:\n",
      "\t analyzing training sample number 500\n",
      "\t analyzing training sample number 1000\n",
      "\t analyzing training sample number 1500\n",
      "\t analyzing training sample number 2000\n",
      "\t analyzing training sample number 2500\n",
      "\t analyzing training sample number 3000\n",
      "just read file number 3 which contains 36554719 audio samples and is named upperroom_16_ryle_8khz.wav Now analying it:\n",
      "\t analyzing training sample number 500\n",
      "\t analyzing training sample number 1000\n",
      "\t analyzing training sample number 1500\n",
      "\t analyzing training sample number 2000\n",
      "\t analyzing training sample number 2500\n",
      "\t analyzing training sample number 3000\n",
      "\t analyzing training sample number 3500\n",
      "\t analyzing training sample number 4000\n",
      "\t analyzing training sample number 4500\n",
      "\t analyzing training sample number 5000\n",
      "\t analyzing training sample number 5500\n",
      "\t analyzing training sample number 6000\n",
      "\t analyzing training sample number 6500\n",
      "\t analyzing training sample number 7000\n",
      "\t analyzing training sample number 7500\n",
      "\t analyzing training sample number 8000\n",
      "\t analyzing training sample number 8500\n",
      "\t analyzing training sample number 9000\n",
      "just read file number 4 which contains 3008270 audio samples and is named vorst_14_machiavelli_8khz.wav Now analying it:\n",
      "\t analyzing training sample number 500\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "#files = [ 'vorst_14_machiavelli_8khz.wav'\n",
    "# ]\n",
    "files = [ 'cousinhenry_01_trollope_8khz.wav',\n",
    "'siegeofcorinth_2_byron_8khz.wav',\n",
    "'upperroom_16_ryle_8khz.wav',\n",
    "'vorst_14_machiavelli_8khz.wav',\n",
    "]\n",
    "\n",
    "#more comments about this calculation? +1 - bias?\n",
    "height_of_one_training_example = 49 * 13 * 2 + 1\n",
    "\n",
    "label = 0\n",
    "all_examples = []\n",
    "for one_file in files:\n",
    "  label += 1\n",
    "  rate, data = scipy.io.wavfile.read(one_file)\n",
    "  total_length_of_wave = data.shape[0]\n",
    "  print (\"just read file number %d which contains %d audio samples and is named %s Now analying it:\" % (label, total_length_of_wave, one_file))\n",
    "  assert rate == 8000, \"rate was %d\" % rate\n",
    "\n",
    "  half_second_length = 4000\n",
    "  start_index_of_half_second = 0\n",
    "  num_training_example_in_this_file = 0\n",
    "  while total_length_of_wave - start_index_of_half_second >= half_second_length:\n",
    "    num_training_example_in_this_file += 1\n",
    "    if num_training_example_in_this_file % 500 == 0:\n",
    "      print (\"\\t analyzing training sample number %d\" % num_training_example_in_this_file)\n",
    "\n",
    "    this_training_example_raw = data[start_index_of_half_second:start_index_of_half_second + half_second_length]\n",
    "    start_index_of_half_second += half_second_length\n",
    "    assert len(this_training_example_raw) == 4000, len(this_training_example_raw)\n",
    "    mfccs = mfcc(this_training_example_raw, 8000)\n",
    "    assert mfccs.shape == (49, 13), mfccs.shape\n",
    "\n",
    "    #Alfredo used 2 here, and changing it doesn't change the output size.\n",
    "    first_derivative = delta(mfccs, 2)\n",
    "    assert first_derivative.shape == (49, 13), first_derivative.shape\n",
    "    all_examples.extend(mfccs.flatten().tolist())\n",
    "    all_examples.extend(first_derivative.flatten().tolist())\n",
    "    all_examples.append(label)\n",
    "    assert len(all_examples) % height_of_one_training_example == 0, \"num_training_example_in_this_file = %d\" % num_training_example_in_this_file\n",
    "\n",
    "all_examples_np = np.array(all_examples)\n",
    "all_examples_np = all_examples_np.reshape((height_of_one_training_example, -1), order='F')\n",
    "\n",
    "#print (\"all_examples_np.shape = %s, so we have %d training samples\" % (all_examples_np.shape, all_examples_np.shape[1]))\n",
    "assert all_examples_np[-1, 0] == 1, \"make sure the last row labels the first column as belonging to file number 1 %s\" % all_examples_np[-1, 0]\n",
    "\n",
    "shuffled_examples = all_examples_np.T\n",
    "np.random.shuffle(shuffled_examples)\n",
    "shuffled_examples = shuffled_examples.T\n",
    "\n",
    "training_pct = 0.8\n",
    "\n",
    "number_of_training_examples = int(math.ceil(all_examples_np.shape[1] * training_pct))\n",
    "\n",
    "X_train = shuffled_examples[0:-1, 0:number_of_training_examples]\n",
    "Y_train = shuffled_examples[-1:, 0:number_of_training_examples]\n",
    "X_dev   = shuffled_examples[0:-1, number_of_training_examples:]\n",
    "Y_dev   = shuffled_examples[-1:, number_of_training_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11853, 1274) (11853, 1) (2963, 1274) (2963, 1)\n",
      "[[3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "# Xs are shape (number of input features, number of data points)\n",
    "# Ys are shape (1, number of data points)\n",
    "# The labels in Y are an integer corresponding to the speaker number.\n",
    "# Before reshape\n",
    "# (1274, 11853) (1, 11853) (1274, 2963) (1, 2963)\n",
    "\n",
    "# In Keras, you want (number of data, attributes)\n",
    "# Want: (see coursera M4 - Keras Tutorial)\n",
    "# (11853, 1274) (11853, 1) (2963, 1274) (2963, 1)\n",
    "# Reshape\n",
    "X_train = X_train.T\n",
    "Y_train = Y_train.T\n",
    "X_dev = X_dev.T\n",
    "Y_dev = Y_dev.T\n",
    "\n",
    "#check\n",
    "print(X_train.shape, Y_train.shape, X_dev.shape, Y_dev.shape)\n",
    "\n",
    "#debugging - to be deleted\n",
    "print(Y_train[100:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 ms, sys: 6.6 ms, total: 11.3 ms\n",
      "Wall time: 9.68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Keras\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#hidden layers - 50 nodes\n",
    "#possible activation functions for hidden layers in Keras: elu (Exponential linear unit), selu (Scaled Exponential Linear Unit), \n",
    "#tanh, sigmoid, exponential, linear\n",
    "#https://keras.io/activations/\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "# Add another (optional):\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "#justification for binary: \n",
    "#\"we compile the model using binary cross-entropy rather than categorical cross-entropy. This may seem counterintuitive \n",
    "# for multi-label classification; however, the goal is to treat each output label as an independent Bernoulli distribution \n",
    "# and we want to penalize each output node independently.\"\n",
    "#quoted from: https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/\n",
    "#more: https://stackoverflow.com/questions/42081257/keras-binary-crossentropy-vs-categorical-crossentropy-performance/46038271\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11853 samples, validate on 2963 samples\n",
      "Epoch 1/50\n",
      "11853/11853 [==============================] - 0s 28us/step - loss: 14.3860 - acc: 0.0596 - val_loss: 14.4147 - val_acc: 0.0327\n",
      "Epoch 2/50\n",
      "11853/11853 [==============================] - 0s 24us/step - loss: 14.3850 - acc: 0.2511 - val_loss: 14.4146 - val_acc: 0.0597\n",
      "Epoch 3/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3850 - acc: 0.3346 - val_loss: 14.4143 - val_acc: 0.0537\n",
      "Epoch 4/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.1614 - val_loss: 14.4142 - val_acc: 0.5521\n",
      "Epoch 5/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.2184 - val_loss: 14.4142 - val_acc: 0.7280\n",
      "Epoch 6/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3848 - acc: 0.2753 - val_loss: 14.4142 - val_acc: 0.0564\n",
      "Epoch 7/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.1994 - val_loss: 14.4142 - val_acc: 0.0638\n",
      "Epoch 8/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.2561 - val_loss: 14.4142 - val_acc: 0.8772\n",
      "Epoch 9/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3848 - acc: 0.4162 - val_loss: 14.4142 - val_acc: 0.0628\n",
      "Epoch 10/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.2878 - val_loss: 14.4142 - val_acc: 0.8839\n",
      "Epoch 11/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.3559 - val_loss: 14.4142 - val_acc: 0.8917\n",
      "Epoch 12/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.1378 - val_loss: 14.4142 - val_acc: 0.0483\n",
      "Epoch 13/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.3021 - val_loss: 14.4142 - val_acc: 0.0388\n",
      "Epoch 14/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3851 - acc: 0.0302 - val_loss: 14.4142 - val_acc: 0.0648\n",
      "Epoch 15/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.1612 - val_loss: 14.4142 - val_acc: 0.1195\n",
      "Epoch 16/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3848 - acc: 0.1299 - val_loss: 14.4142 - val_acc: 0.0749\n",
      "Epoch 17/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.1794 - val_loss: 14.4143 - val_acc: 0.0294\n",
      "Epoch 18/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3851 - acc: 0.1613 - val_loss: 14.4142 - val_acc: 0.8758\n",
      "Epoch 19/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.2847 - val_loss: 14.4142 - val_acc: 0.8890\n",
      "Epoch 20/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.3197 - val_loss: 14.4143 - val_acc: 0.0236\n",
      "Epoch 21/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3849 - acc: 0.4011 - val_loss: 14.4142 - val_acc: 0.9058\n",
      "Epoch 22/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3851 - acc: 0.5070 - val_loss: 14.4143 - val_acc: 0.0297\n",
      "Epoch 23/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3850 - acc: 0.3902 - val_loss: 14.4145 - val_acc: 0.0246\n",
      "Epoch 24/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3849 - acc: 0.2765 - val_loss: 14.4142 - val_acc: 0.0587\n",
      "Epoch 25/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3848 - acc: 0.2685 - val_loss: 14.4142 - val_acc: 0.0439\n",
      "Epoch 26/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3851 - acc: 0.1357 - val_loss: 14.4146 - val_acc: 0.0304\n",
      "Epoch 27/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.1093 - val_loss: 14.4143 - val_acc: 0.2545\n",
      "Epoch 28/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3848 - acc: 0.3139 - val_loss: 14.4142 - val_acc: 0.8657\n",
      "Epoch 29/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.1983 - val_loss: 14.4142 - val_acc: 0.0395\n",
      "Epoch 30/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3849 - acc: 0.3672 - val_loss: 14.4144 - val_acc: 0.9092\n",
      "Epoch 31/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.4223 - val_loss: 14.4143 - val_acc: 0.0287\n",
      "Epoch 32/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.3681 - val_loss: 14.4143 - val_acc: 0.0283\n",
      "Epoch 33/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3855 - acc: 0.4253 - val_loss: 14.4146 - val_acc: 0.9008\n",
      "Epoch 34/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3849 - acc: 0.3677 - val_loss: 14.4143 - val_acc: 0.8805\n",
      "Epoch 35/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3848 - acc: 0.1979 - val_loss: 14.4142 - val_acc: 0.0479\n",
      "Epoch 36/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.1402 - val_loss: 14.4142 - val_acc: 0.0719\n",
      "Epoch 37/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3848 - acc: 0.2051 - val_loss: 14.4142 - val_acc: 0.8988\n",
      "Epoch 38/50\n",
      "11853/11853 [==============================] - 0s 20us/step - loss: 14.3850 - acc: 0.2572 - val_loss: 14.4142 - val_acc: 0.8893\n",
      "Epoch 39/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.4060 - val_loss: 14.4141 - val_acc: 0.8448\n",
      "Epoch 40/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3854 - acc: 0.1930 - val_loss: 14.4154 - val_acc: 0.0216\n",
      "Epoch 41/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3852 - acc: 0.1337 - val_loss: 14.4145 - val_acc: 0.0574\n",
      "Epoch 42/50\n",
      "11853/11853 [==============================] - 0s 23us/step - loss: 14.3849 - acc: 0.1777 - val_loss: 14.4141 - val_acc: 0.0699\n",
      "Epoch 43/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.3019 - val_loss: 14.4141 - val_acc: 0.3962\n",
      "Epoch 44/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.2685 - val_loss: 14.4141 - val_acc: 0.0493\n",
      "Epoch 45/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3848 - acc: 0.2708 - val_loss: 14.4141 - val_acc: 0.8940\n",
      "Epoch 46/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.4970 - val_loss: 14.4141 - val_acc: 0.0469\n",
      "Epoch 47/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3848 - acc: 0.4579 - val_loss: 14.4142 - val_acc: 0.0270\n",
      "Epoch 48/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3849 - acc: 0.4243 - val_loss: 14.4141 - val_acc: 0.8927\n",
      "Epoch 49/50\n",
      "11853/11853 [==============================] - 0s 21us/step - loss: 14.3849 - acc: 0.4263 - val_loss: 14.4142 - val_acc: 0.9136\n",
      "Epoch 50/50\n",
      "11853/11853 [==============================] - 0s 22us/step - loss: 14.3851 - acc: 0.4734 - val_loss: 14.4143 - val_acc: 0.0385\n",
      "CPU times: user 17.9 s, sys: 3 s, total: 20.9 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_object = model.fit(X_train, Y_train, epochs=50, batch_size=512, verbose=1, shuffle=True,\n",
    "         validation_data=(X_dev, Y_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [14.44058697166533, 14.43667934120325, 14.432600462955676, 14.448236995881127, 14.438385342248099, 14.429574998294909, 14.427746764075865, 14.425457743909606, 14.425772288422548, 14.422923814514139, 14.426620242646365, 14.422328138528464, 14.422537622120265, 14.42210616029037, 14.423429416395143, 14.42345581479544, 14.423060645696644, 14.422769702611403, 14.421398833278381, 14.42053453140954, 14.422290708340386, 14.424026167718615, 14.420126825500653, 14.419557930286214, 14.418518942512051, 14.419152651531569, 14.418233170768437, 14.421295351407595, 14.417680538549561, 14.41798743467817, 14.416661273133622, 14.416948939351427, 14.416808567375417, 14.416963274399253, 14.416558082547093, 14.416504896616477, 14.41633537754673, 14.416512165204761, 14.416161806568116, 14.416616634545276, 14.415617555933066, 14.416565983270496, 14.415150217538422, 14.415574672774934, 14.415621304326955, 14.415544983989035, 14.41498395956492, 14.414190758735073, 14.414796732021593, 14.4150899326403], 'val_acc': [0.26223422199175883, 0.16604792436071236, 0.5700303746907244, 0.6550793113476756, 0.1167735403332604, 0.5889301384939682, 0.2966587918254519, 0.13094836315048977, 0.716503543786169, 0.5791427606853166, 0.047924400950017265, 0.06074924063952115, 0.7549780629552622, 0.8299021262636549, 0.0516368545418328, 0.5055686803311461, 0.045899426262200865, 0.11913601075963237, 0.07559905497157972, 0.8501518730010047, 0.0823489706428961, 0.018562267974164895, 0.8623017213692988, 0.052649341885741, 0.04117448532144805, 0.053999325010951935, 0.038812014852328915, 0.055011812354860135, 0.7431657105090849, 0.03239959500757698, 0.07154910563869409, 0.034087073914090646, 0.0587242659491902, 0.024974687818916836, 0.04623692204098906, 0.04927438407271366, 0.0496118798540164, 0.8963887951802934, 0.898076274086807, 0.048936888293925465, 0.11947350664151668, 0.07289908876641957, 0.8697266284573775, 0.5379682755172555, 0.022612217349797698, 0.7948025650484032, 0.02632467094412777, 0.04016199797753985, 0.037799527508420715, 0.0992237597080328], 'loss': [14.412207839841592, 14.414792758185662, 14.410031994113456, 14.412082703095654, 14.40211411225668, 14.404856238738903, 14.401472195063947, 14.39113661943785, 14.390403814660964, 14.389733399076018, 14.389004513994708, 14.389520963274416, 14.39015750954204, 14.388751780163092, 14.388165952022252, 14.38964439816267, 14.391136390694403, 14.389227798817219, 14.389617913082905, 14.389501092203215, 14.389549994864947, 14.391160168426907, 14.3895044106326, 14.39131188897516, 14.39049958189077, 14.388231729320621, 14.386687791670344, 14.386256377827534, 14.386380523485965, 14.386258646434724, 14.385580783854614, 14.385671272123352, 14.385283166744895, 14.385312927289219, 14.385444320969006, 14.385308270513544, 14.385189960267004, 14.385133443256475, 14.385377338885416, 14.3853334308445, 14.385360202034606, 14.385905392691122, 14.385506007517076, 14.385310601476053, 14.385446005769493, 14.385815761224697, 14.385331313338328, 14.385351648815853, 14.385395389583596, 14.385619086353506], 'acc': [0.31662870167750584, 0.30836075263506935, 0.30414241123282937, 0.32346241460750247, 0.3455665231776883, 0.34885682949338553, 0.34109508133352956, 0.32346241452830116, 0.3074327174655538, 0.3312241626648996, 0.33088669519047087, 0.27663882571937043, 0.28726904581087276, 0.3178098371719454, 0.3183160380533473, 0.2962962962648672, 0.28895638234983123, 0.2621277313571655, 0.2671053741480201, 0.2898000506200962, 0.25563148569950855, 0.3216907111218355, 0.29941786889387234, 0.3527377034947408, 0.2625495655460417, 0.24432633069560647, 0.29899603484461984, 0.2626339323378048, 0.2271998650187341, 0.23302117624957078, 0.32396861554602674, 0.3027081751907907, 0.2572344553932745, 0.2941871255316896, 0.2833881716803439, 0.26794904243619966, 0.25099131003579117, 0.28094153378262837, 0.37256390787142496, 0.3209314097753358, 0.23099637222015473, 0.24888213953644597, 0.16088753910263026, 0.3788070530604483, 0.3257403188160901, 0.3828566607609888, 0.2676959420712821, 0.24289209482799923, 0.25622205351748306, 0.17421749767362643]}\n"
     ]
    }
   ],
   "source": [
    "print(history_object.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230 venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
